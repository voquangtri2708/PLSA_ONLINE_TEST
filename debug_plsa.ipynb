{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import codecs\n",
    "import numpy as np\n",
    "from numpy import zeros, int8, log\n",
    "from pyvi import ViTokenizer\n",
    "from pylab import random\n",
    "\n",
    "class PLSA:\n",
    "    def __init__(self, K, maxIteration=30, threshold=10.0, topicWordsNum=5):\n",
    "        self.K = K  # Số chủ đề\n",
    "        self.maxIteration = maxIteration  # Số lần lặp tối đa\n",
    "        self.threshold = threshold  # Ngưỡng dừng\n",
    "        self.topicWordsNum = topicWordsNum  # Số từ hàng đầu trong mỗi chủ đề\n",
    "        self.Pz = zeros(self.K)  # Xác suất của các chủ đề\n",
    "        self.lamda = None  # Ma trận lambda P(d|z)\n",
    "        self.theta = None  # Ma trận theta P(w|z)\n",
    "        self.p = None  # Ma trận xác suất trung gian P(z|d,w)\n",
    "\n",
    "    def initializeParameters(self, N, M, Pz, lamda, theta):\n",
    "        \n",
    "        self.Pz = Pz\n",
    "        self.lamda = lamda\n",
    "        self.theta = theta\n",
    "\n",
    "        print(\"Initialization\")\n",
    "        print(\"Pz\\n\", self.Pz)\n",
    "        print(\"theta\\n\", self.theta)\n",
    "        print(\"lamda\\n\", self.lamda)\n",
    "\n",
    "    def EStep(self, N, M):\n",
    "        \"\"\"\n",
    "        Thực hiện bước E: Tính toán ma trận xác suất P(z|d,w).\n",
    "        \"\"\"\n",
    "        for i in range(0, N):\n",
    "            for j in range(0, M):\n",
    "                denominator = np.sum(self.Pz[k] * self.lamda[i,k] * self.theta[j,k] for k in range(self.K))\n",
    "                if denominator == 0:\n",
    "                    self.p[i,j,:] = 1.0/self.K\n",
    "                else:\n",
    "                    for k in range(self.K):\n",
    "                        self.p[i,j,k] = (self.Pz[k] * self.lamda[i,k] * self.theta[j,k]) / denominator    \n",
    "\n",
    "\n",
    "    def MStep(self, N, M, X):\n",
    "        # Cập nhật theta (P(w|z))\n",
    "        for k in range(self.K):\n",
    "            for j in range(M):  # Loop over words (M should be the number of words)\n",
    "                self.theta[j,k] = np.sum(X[i, j] * self.p[i, j, k] for i in range(N))\n",
    "            self.theta[:,k] /= np.sum(self.theta[:,k])\n",
    "\n",
    "        # Cập nhật lambda (P(d|z))\n",
    "        for k in range(self.K):\n",
    "            for i in range(N):  # Loop over documents (N should be the number of documents)\n",
    "                self.lamda[i, k] = np.sum(X[i, j] * self.p[i, j, k] for j in range(M))\n",
    "            self.lamda[:, k] /= np.sum(self.lamda[:, k])\n",
    "\n",
    "        # Cập nhật Pz\n",
    "        for k in range(self.K):\n",
    "            self.Pz[k] = np.sum(self.p[i, j, k] * X[i, j] for i in range(N) for j in range(M))\n",
    "\n",
    "        # Chuẩn hóa Pz: chia cho tổng số lần xuất hiện của tất cả các từ và tài liệu\n",
    "        total = np.sum(X)\n",
    "        self.Pz /= total\n",
    "\n",
    "\n",
    "        \n",
    "    def LogLikelihood(self, N, M, X):\n",
    "        loglikelihood = 0\n",
    "        for i in range(0, N):\n",
    "            for j in range(0, M):\n",
    "                tmp = 0\n",
    "                for k in range(0, self.K):\n",
    "                    tmp += self.theta[j,k] * self.lamda[i, k] * self.Pz[k]\n",
    "                if tmp > 0:\n",
    "                    loglikelihood += X[i, j] * log(tmp)\n",
    "        return loglikelihood\n",
    "\n",
    "    def train(self, X, M, N):\n",
    "        # N, M, X = self.preprocessing(dataset)\n",
    "        # self.initializeParameters(N, M)\n",
    "\n",
    "        oldLoglikelihood = 1\n",
    "        newLoglikelihood = 1\n",
    "        self.p = zeros((N,M,self.K))\n",
    "        for i in range(0, 1):\n",
    "            self.EStep(N, M)\n",
    "            self.MStep(N, M, X)\n",
    "            # print(self.Pz)\n",
    "            newLoglikelihood = self.LogLikelihood(N, M, X)\n",
    "            # if oldLoglikelihood != 1 and newLoglikelihood - oldLoglikelihood < self.threshold:\n",
    "            #     break\n",
    "            oldLoglikelihood = newLoglikelihood\n",
    "            # print(newLoglikelihood)\n",
    "\n",
    "\n",
    "            print(\"Step: \", i)\n",
    "            print(\"Pz\\n\", self.Pz)\n",
    "            print(\"theta\\n\", self.theta)\n",
    "            print(\"lamda\\n\", self.lamda)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [[1, 2, 0, 0, 0, 0],\n",
    "     [3, 1, 0, 0, 0, 0],\n",
    "     [2, 0, 0, 0, 0, 0],\n",
    "     [3, 3, 2, 3, 2, 4],\n",
    "     [0, 0, 3, 2, 0, 0],\n",
    "     [0, 0, 4, 1, 0, 0],\n",
    "     [0, 0, 0, 0, 4, 3],\n",
    "     [0, 0, 0, 0, 2, 1],\n",
    "     [0, 0, 0, 0, 3, 2],\n",
    "     [0, 0, 1, 0, 2, 3]]\n",
    "x = np.array(x)\n",
    "n = 10\n",
    "m = 6\n",
    "lamda = [[0.022, 0.016, 0.010],\n",
    "          [0.018, 0.133, 0.166],\n",
    "          [0.242, 0.058, 0.133],\n",
    "          [0.123, 0.088, 0.145],\n",
    "          [0.016, 0.030, 0.044],\n",
    "          [0.020, 0.167, 0.056],\n",
    "          [0.147, 0.129, 0.201],\n",
    "          [0.188, 0.156, 0.039],\n",
    "          [0.146, 0.114, 0.008],\n",
    "          [0.077, 0.110, 0.199]]\n",
    "\n",
    "theta = [[0.020, 0.008, 0.048],\n",
    "        [0.294, 0.255, 0.329],\n",
    "        [0.204, 0.138, 0.178],\n",
    "        [0.200, 0.146, 0.007],\n",
    "        [0.186, 0.196, 0.233],\n",
    "        [0.096, 0.257, 0.205]]\n",
    "\n",
    "Pz = [0.525, 0.407, 0.068]\n",
    "Pz = np.array(Pz)\n",
    "theta = np.array(theta)\n",
    "lamda = np.array(lamda)\n",
    "# k = 3\n",
    "model = PLSA(K=3, maxIteration=70,threshold=5.0, topicWordsNum=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization\n",
      "Pz\n",
      " [0.525 0.407 0.068]\n",
      "theta\n",
      " [[0.02  0.008 0.048]\n",
      " [0.294 0.255 0.329]\n",
      " [0.204 0.138 0.178]\n",
      " [0.2   0.146 0.007]\n",
      " [0.186 0.196 0.233]\n",
      " [0.096 0.257 0.205]]\n",
      "lamda\n",
      " [[0.022 0.016 0.01 ]\n",
      " [0.018 0.133 0.166]\n",
      " [0.242 0.058 0.133]\n",
      " [0.123 0.088 0.145]\n",
      " [0.016 0.03  0.044]\n",
      " [0.02  0.167 0.056]\n",
      " [0.147 0.129 0.201]\n",
      " [0.188 0.156 0.039]\n",
      " [0.146 0.114 0.008]\n",
      " [0.077 0.11  0.199]]\n",
      "Step:  0\n",
      "Pz\n",
      " [0.45821703 0.42984328 0.11193969]\n",
      "theta\n",
      " [[0.18047836 0.07426782 0.38657384]\n",
      " [0.12401997 0.08908869 0.09059273]\n",
      " [0.14647945 0.21328815 0.14864023]\n",
      " [0.12504987 0.11053789 0.00401299]\n",
      " [0.26621435 0.20382629 0.16502518]\n",
      " [0.15775801 0.30899117 0.20515504]]\n",
      "lamda\n",
      " [[0.07725898 0.03240679 0.02948333]\n",
      " [0.02389351 0.07331716 0.24756306]\n",
      " [0.06149752 0.00487221 0.04300727]\n",
      " [0.37166842 0.22132574 0.29306347]\n",
      " [0.08699721 0.09425399 0.0655822 ]\n",
      " [0.03356232 0.15913385 0.03517836]\n",
      " [0.11489448 0.13006763 0.12731601]\n",
      " [0.05851531 0.05761792 0.00939963]\n",
      " [0.09880349 0.09761685 0.00434082]\n",
      " [0.07290875 0.12938786 0.14506584]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_7080\\139751936.py:36: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  denominator = np.sum(self.Pz[k] * self.lamda[i,k] * self.theta[j,k] for k in range(self.K))\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_7080\\139751936.py:48: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  self.theta[j,k] = np.sum(X[i, j] * self.p[i, j, k] for i in range(N))\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_7080\\139751936.py:54: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  self.lamda[i, k] = np.sum(X[i, j] * self.p[i, j, k] for j in range(M))\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_7080\\139751936.py:59: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  self.Pz[k] = np.sum(self.p[i, j, k] * X[i, j] for i in range(N) for j in range(M))\n"
     ]
    }
   ],
   "source": [
    "model.initializeParameters(n,m,Pz,lamda, theta)\n",
    "model.train(x,m,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import codecs\n",
    "import numpy as np\n",
    "import pickle\n",
    "from numpy import zeros, int8, log\n",
    "from pyvi import ViTokenizer\n",
    "from pylab import random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class PLSA:\n",
    "    def __init__(self, K, maxIteration=30, threshold=10.0, topicWordsNum=5):\n",
    "        self.K = K  # Số chủ đề\n",
    "        self.maxIteration = maxIteration  # Số lần lặp tối đa\n",
    "        self.threshold = threshold  # Ngưỡng dừng\n",
    "        self.topicWordsNum = topicWordsNum  # Số từ hàng đầu trong mỗi chủ đề\n",
    "        self.word2id = {}  \n",
    "        self.id2word = {}  \n",
    "        self.Pz = zeros(self.K)  # Xác suất của các chủ đề\n",
    "        self.lamda = None  # Ma trận lambda P(d|z)\n",
    "        self.theta = None  # Ma trận theta P(w|z)\n",
    "        self.p = None  # Ma trận xác suất trung gian P(z|d,w)\n",
    "        self.stopwordsFilePath='stopwords.dic'  \n",
    "    \n",
    "    def preprocessing(self, dataset):\n",
    "        \"\"\"\n",
    "        Xử lý trước tài liệu, bao gồm tokenization, loại bỏ stopwords và xây dựng\n",
    "        word2id, id2word và ma trận tần suất từ.\n",
    "        \"\"\"\n",
    "        # Load stopwords\n",
    "        file = codecs.open(self.stopwordsFilePath, 'r', 'utf-8')\n",
    "        self.stopwords = [line.lower().strip() for line in file]\n",
    "        file.close()\n",
    "\n",
    "        documents = dataset\n",
    "        N = len(documents)  # Số tài liệu\n",
    "        wordCounts = []\n",
    "        currentId = 0\n",
    "\n",
    "        # Xây dựng word2id và id2word, đếm số lượng từ\n",
    "        for document in documents:\n",
    "            segList = ViTokenizer.tokenize(document).split()\n",
    "            wordCount = {}\n",
    "            for word in segList:\n",
    "                word = word.lower().strip()\n",
    "                if len(word) > 1 and not re.search('[0-9]', word) and word not in self.stopwords:\n",
    "                    if word not in self.word2id:\n",
    "                        self.word2id[word] = currentId\n",
    "                        self.id2word[currentId] = word\n",
    "                        currentId += 1\n",
    "                    if word in wordCount:\n",
    "                        wordCount[word] += 1\n",
    "                    else:\n",
    "                        wordCount[word] = 1\n",
    "            wordCounts.append(wordCount)\n",
    "\n",
    "        M = len(self.word2id)  # Số từ\n",
    "        X = zeros([N, M], int8)\n",
    "        for word in self.word2id.keys():\n",
    "            j = self.word2id[word]\n",
    "            for i in range(0, N):\n",
    "                if word in wordCounts[i]:\n",
    "                    X[i, j] = wordCounts[i][word]\n",
    "\n",
    "        return N, M, X\n",
    "\n",
    "    def initializeParameters(self, N, M):\n",
    "        self.lamda = random([N, self.K])  # P(d|z)\n",
    "        self.theta = random([M, self.K])  # P(w|z)\n",
    "        self.Pz = random([self.K])  # P(z)\n",
    "        self.Pz /= sum(self.Pz)  # Chuẩn hóa Pz để tổng bằng 1\n",
    "\n",
    "        self.p = np.zeros((N, M, self.K))  # Ma trận xác suất P(z|d,w)\n",
    "\n",
    "        # Chuẩn hóa lambda và theta\n",
    "        for k in range(0, self.K):\n",
    "            self.lamda[:, k] /= sum(self.lamda[:, k])\n",
    "            self.theta[:, k] /= sum(self.theta[:, k])\n",
    "            \n",
    "\n",
    "    def EStep(self, N, M, X):\n",
    "        \"\"\"\n",
    "        Thực hiện bước E: Tính toán ma trận xác suất P(z|d,w).\n",
    "        \"\"\"\n",
    "        for i in range(0, N):\n",
    "            for j in range(0, M):\n",
    "                denominator = np.sum(self.Pz[k] * self.lamda[i,k] * self.theta[j,k] for k in range(self.K))\n",
    "                if denominator == 0:\n",
    "                    self.p[i,j,:] = 1.0/self.K\n",
    "                else:\n",
    "                    for k in range(self.K):\n",
    "                        self.p[i,j,k] = (self.Pz[k] * self.lamda[i,k] * self.theta[j,k]) / denominator    \n",
    "\n",
    "    def MStep(self, N, M, X):\n",
    "        # Cập nhật theta (P(w|z))\n",
    "        for k in range(0, self.K):\n",
    "            for j in range(0, M):\n",
    "                self.theta[j,k] = np.sum(X[i,j] * self.p[i,j,k] for i in range(N))\n",
    "            self.theta[:, k] /= np.sum(self.theta[:, k])\n",
    "\n",
    "        # Cập nhật lambda (P(d|z))\n",
    "        for k in range(self.K):\n",
    "            for i in range(N):\n",
    "                self.lamda[i,k] = np.sum(X[i,j] * self.p[i,j,k] for j in range(M))\n",
    "            self.lamda[:, k] /= np.sum(self.lamda[:, k])\n",
    "\n",
    "        for k in range(self.K):\n",
    "            self.Pz[k] = np.sum(self.p[i,j,k] * X[i,j] for i in range(N) for j in range(M))\n",
    "\n",
    "        # Chuẩn hóa Pz: chia cho tổng số lần xuất hiện của tất cả các từ và tài liệu\n",
    "        total = np.sum(X)\n",
    "        self.Pz /= total\n",
    "\n",
    "\n",
    "        \n",
    "    def LogLikelihood(self, N, M, X):\n",
    "        loglikelihood = 0\n",
    "        for i in range(0, N):\n",
    "            for j in range(0, M):\n",
    "                tmp = 0\n",
    "                for k in range(0, self.K):\n",
    "                    tmp += self.theta[j, k] * self.lamda[i, k] * self.Pz[k]\n",
    "                if tmp > 0:\n",
    "                    loglikelihood += X[i, j] * log(tmp)\n",
    "        return loglikelihood\n",
    "\n",
    "    def train(self, dataset):\n",
    "        N, M, X = self.preprocessing(dataset)\n",
    "        self.initializeParameters(N, M)\n",
    "\n",
    "        oldLoglikelihood = 1\n",
    "        newLoglikelihood = 1\n",
    "        # print(\"training\")\n",
    "        for i in range(0, self.maxIteration):\n",
    "            self.EStep(N, M, X)\n",
    "            self.MStep(N, M, X)\n",
    "            # print(self.Pz)\n",
    "            newLoglikelihood = self.LogLikelihood(N, M, X)\n",
    "            if oldLoglikelihood != 1 and newLoglikelihood - oldLoglikelihood < self.threshold:\n",
    "                break\n",
    "            oldLoglikelihood = newLoglikelihood\n",
    "            # print(newLoglikelihood)\n",
    "\n",
    "        topic = self.get_top_words()\n",
    "        return self.p, self.Pz, self.lamda, self.theta, topic, self.id2word\n",
    "\n",
    "    def get_top_words(self):\n",
    "        topic = []\n",
    "        for i in range(0, self.K):\n",
    "            topicword = []\n",
    "            ids = self.theta[:, i].argsort()\n",
    "            for j in ids:\n",
    "                topicword.insert(0, self.id2word[j])\n",
    "            tmp = ''\n",
    "            for word in topicword[0:min(self.topicWordsNum, len(topicword))]:\n",
    "                tmp += word + ' '\n",
    "            topic.append(tmp)\n",
    "        return topic\n",
    "\n",
    "\n",
    "    def test(self, data_test):\n",
    "        segList= ViTokenizer.tokenize(data_test[0])    \n",
    "        xtest = zeros(len(self.id2word))\n",
    "        for word in segList.split(' '):\n",
    "            word = word.lower().strip()\n",
    "            # print(word)\n",
    "            for i in range(len(self.id2word)):\n",
    "                if word == self.id2word[i]:\n",
    "                    xtest[i] += 1\n",
    "\n",
    "        z = []\n",
    "        for k in range(self.K):\n",
    "            p_new = 1\n",
    "            for i in range(len(xtest)):\n",
    "                if xtest[i] != 0:\n",
    "                    # if self.theta[k,i] > 1e-6:\n",
    "                        p_new *= self.theta[i, k] * xtest[i]\n",
    "                        # print(p_new)\n",
    "            if p_new == 1:\n",
    "                z.append(0)\n",
    "            else:\n",
    "                p_new *= self.Pz[k]\n",
    "                z.append(p_new)\n",
    "        # print(z)\n",
    "\n",
    "        if all(i == 0 for i in z):\n",
    "            return \"Khong thuoc chu de nao trong cac chu de tren\"  \n",
    "        else:\n",
    "            main_topic = z.index(max(z))\n",
    "            return 'Pz'+str(main_topic)\n",
    "\n",
    "\n",
    "\n",
    "    def save_model(self, filename):\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump({\n",
    "                'Pz': self.Pz,\n",
    "                'theta': self.theta,\n",
    "                'lamda': self.lamda,\n",
    "                'id2word': self.id2word,\n",
    "                'word2id': self.word2id,\n",
    "            }, f)\n",
    "\n",
    "    def load_model(self, filename):\n",
    "        with open(filename, 'rb') as f:\n",
    "            params = pickle.load(f)\n",
    "            self.Pz = params['Pz']\n",
    "            self.theta = params['theta']\n",
    "            self.lamda = params['lamda']\n",
    "            self.id2word = params['id2word']\n",
    "            self.word2id = params['word2id']\n",
    "        topic = self.get_top_words()\n",
    "        self.K = len(self.Pz)\n",
    "        return self.p, self.Pz, self.lamda, self.theta, topic, self.id2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4368\\1933223508.py:88: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  denominator = np.sum(self.Pz[k] * self.lamda[i,k] * self.theta[j,k] for k in range(self.K))\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4368\\1933223508.py:99: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  self.theta[j,k] = np.sum(X[i,j] * self.p[i,j,k] for i in range(N))\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4368\\1933223508.py:105: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  self.lamda[i,k] = np.sum(X[i,j] * self.p[i,j,k] for j in range(M))\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4368\\1933223508.py:109: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  self.Pz[k] = np.sum(self.p[i,j,k] * X[i,j] for i in range(N) for j in range(M))\n"
     ]
    }
   ],
   "source": [
    "file = codecs.open('data_train.txt', 'r', 'utf-8')\n",
    "train_data = [document.strip() for document in file] \n",
    "file.close()\n",
    "\n",
    "\n",
    "model = PLSA(K=3, maxIteration=70,threshold=5.0, topicWordsNum=4)\n",
    "\n",
    "# m,n,x = model.preprocessing(dataset=train_data)\n",
    "p, Pz, lamda, theta, wordTop, id2w = model.train(dataset=train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pz [0.29898097 0.43451343 0.2665056 ]\n",
      "['đại_học việt_nam phát_triển trường ', 'nước theo quán ăn ', 'trường thi điểm học_sinh ']\n"
     ]
    }
   ],
   "source": [
    "print(\"Pz\", Pz)\n",
    "print(wordTop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74704.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
